Definitions:
* Class - The class is the factory and the blueprint for an instance
* Instance - A constructed object of the class
* Type - Indicates the class to which the instance belongs to
* Attribute - Any object value: object.Attribute
* Method - A "callable attribute" defined in the class

More Info:
* Classes are "instance factories"
* Classes define an "instance blueprint"
* Instances know to which class they belong ("type")
* Instances can access variables defined in the class
* Object - An object is a unit of data (having one or more attributes), of a particular class or type with associated functionality (methods).
* Self - self is the instance upon which the method was called

6 Points to Understanding Classes
---------------------------------
1) An instance of a class knows what class it's from
2) Vars defined in the class are available to the instance
3) A method on an instance passes instance as the first argument to the method (named self in the method)
4) Instances have their own data called instance attributes
5) Variables defined in the class are called class attributes
6) When we read an attribute, Python looks for it first in the instance, and then the class

More Info:
* Instance methods are variables defined in the class
* They are accessed through the instance: instance.method()
* When called through the instance, the instance is automatically passed as 1st argument to the method
* Bound Methods: Because of this automatic passing of instance, instance methods are called bound methods
* Instance data takes the form of instance attribute values, set and accessed through object.attribute syntax


3 Pillars of OOP:
1) Encapsulation - Ensures the integrity of the data in the object by using setter and getter methods.
2) Inheritance - Inheritance refers to a new feature that we'll look at now the ability to have one class inherit the attributes of another class.
3) Polymorphism - This refers to a design in which objects of dissimilar types can be treated in the same manner. More specifically it refers to two classes that have methods of the same name.
                  We call this a common interface because we can call the same method on either type of object.
                  Here the methods are different but conceptually similar. This allows for expressiveness in design. A group of related classes implement same action
                  Ex: len('hello), len([1,2,3]) and len({'a': 1, 'b': 2}) are all using length method which gives similar expected o/p but are implemented differently

Object.Attribute Lookup Hierarchy:
1) In the instance
2) In the class
3) Any class from which this class inherits

* An inheriting class - Child class / Derived class / Subclass
* An inherited class - Parent class / Base class / Superclass

Ineritance Hierarchy:
* Classes can be organized into an inheritance hierarchy
* A child class can access the attributes of all parent (grandparent, etc) Classes

Inheriting the Constructor:
* __init__ is like any other method; it can be inherited
* If a class does not have an __init__ constructor, Python will check its parent class to see if it can find one. As soon as it finds one, Python calls it and stops looking
* We can use the super() funtion to call methods in the parent class
* We may want to initialize in the parent (for general functionality) as well as our own class (for our class specific functionality)

Method Resolution Order:
It is the order in which base classes are searched for a member during lookup. A class may inherit from multiple classes and any of these parent classes may themselves
inherit from one or more other classes.

Topology 1:
                            |class A(object):
                                def dothis(self):|
                                    ^
                                    |
                                    |
                                    |                   |class C(object):    
                                |class B(A):             ^  def dothis(self):|
                                    pass |              /
                                        ^              /
                                         \            /
                                          \          /
                                           \        /
                                        |class D(B,C):
                                                pass |  

                            d_inst=D()
                            d_inst.dothis()
                            # which dothis() will it call ? - Depth-first or Breadth-first
                            #mro: D-B-A-C

Python will check the instance then the class then any parent classes and then what we may call grandparent classes to find the attribute in the case of multiple inheritance.
By default Python will use a depth first search for an attribute in a class hierarchy.

Topology 2: (Dimond shaped)

                                        |class A(object):
                                            def dothis(self):|
                                            ^            ^
                                           /              \
                                          /                \
                                         /                  \
                                        /               |class C(object):    
                                |class B(A):             ^  def dothis(self):|
                                    pass |              /
                                        ^              /
                                         \            /
                                          \          /
                                           \        /
                                        |class D(B,C):
                                                pass |  

                            d_inst=D()
                            d_inst.dothis()
                            # which dothis() will it call ? - Depth-first or Breadth-first
                            #mro: D-B-C-A

Things get a little more complicated if the same class appears in two other classes inheritance. Here the depth first approach will provide the order as D-B-A-C-A.
As "A" is repeated twice and to remove ambiguity, Python removes the earlier appearances of repeated class and hence the order becomes D-B-C-A.
So, when two classes inherit from the same class, Python eliminates the first mention of that class from the mro.

Decorators-> Class and Static Methods:
* Instance methods are designed to work on instance. In the instance methods, instance is the first argument (self). Because of this automatic passing, instance is bound to the method.
* But some of the functionality might not actually have to do with the instance itself but might be relating directly to the class itself dealing with class data. 
* The methods where the instance is not required and these methods we can call class methods.
* A class method takes the class (not instance) as argument and works with the class object. Hence they are not bound to the instance. 
* We can use the class object to call the method directly.
* Decorator is a processor that modifies a function. It modifies the default binding that instance methods provide. 
* By providing this decorator, we are letting know that its not bound to instance
* The static method decorator is neither a class method which would work with the class or an instance method which would work with the instance. Instead tt's just a utility class.
* The static method belongs in the class code because it works with the class code but it's neither an instance nor a class method.
* A static method requires no argument and does not work with the class or instance.

Abstract Base Class:
* When we're working in a collaborative environment with other developers who are creating classes that will fit into a larger hierarchy,
  we may want to define a class that indicates and enforces what methods the subclass should implement. This we call as abstract class
* An abstract class is a kind of "model" for other classes to be defined. It is not designed to construct instances but can be sub-classed by regular classes
* Abstract classes can define an interface or methods that must be implemented by its subclasses
* The python abc module enables the creation of abstract base classes
* Abstract base classes can't be instantiated directly

Inheritance Possibilities:
* When working in a child class we can choose to implement parent class methods in one of the following ways:
    * Inherit: simply use the parent class defined method
    * Override: Provide child's own version of a method
    * Extend: Do work in addition to that in parent's method
    * Abstract: Implement abstract method that parent requires

Composition Vs Inheritance:
* Class Composition can be an alternative to Inheritance
* Inheritance can be brittle (a change may requrie changes elsewhere). This is becuase inheritance establishes dependencies between parent and child classes
* Composition approach uses independent classes that can work together but aren't related
* As long as the interface is maintained, interactions between classes will work. This is in a way polymorphic

Operators in classes:
* ADD Operator
    * if var1='hello' & var2='world!' then var1+var2 will result in 'hello world!'
    * The above is same as var1.__add__(var2). The magic method __add__ is called where '+' is used
    * This works for var3=5, var4=10 and var3.__add__(var4) will be 15 and same works for lists as well
* The same is true for any operators like +, -, *, /, in and built-in functions len() and str()
* These operators/functions also respond similarly when we use them in our classes
* Core syntax features translate to magic method calls
* When we add magic method in our own classes, we can make use of the operator too
* 'abc' in var resolves to var.__contains__('abc')
* var=='abc' resolves to var.__eq__('abc')
* var[1] resolves to var.__getitem__(1)
* var[1:3] resolves to var.__getslice__(1,3)
* len(var) resolves to var.__len__()
* print(var) resolves to var.__repr__()

Magic Methods __str__() and __repr__():
* The __str__() and __repr__() methods can be helpful in printing useful information about an object
* The __str__() method returns a human-readable, or informal, string representation of an object
* This __str__() method is called by the built-in print(), str(), and format() functions
* If you don’t define a __str__() method for a class, then the built-in object implementation calls the __repr__() method instead
* The repr method is called implicitly when we do certain operations on the object
* The __repr__() method returns a more information-rich, or official, string representation of an object. This method is called by the built-in repr() function. 
* Note that str() and repr() return the same value, because str() calls __repr__() when __str__() isn’t implemented.

if __name__ == '__main__':
    * This gate basically says that if we execute the program containing this directly, then we will execute all the lines under it
    * But if we import the program containing this gate from another script, then all of the code from this program will get loaded but the code under this gate won't get executed.

Inheriting from built-ins:
* Python let our classes inherit from built-in classes
* An inheriting (child) class of a built-in, shares all the same attributes(including methods) of built-in
* We can take advantage of core built-in functionality, but customize selected operations too

Decorators:
* A decorator function is basically a function that adds new functionality to a function that is passed as argument.

Properties (@property) in Python:
* The @property is a built-in decorator for the property() function in Python. 
* It is used to give "special" functionality to certain methods to make them act as getters, setters, or deleters when we define properties in a class.
* Specifically, you can define three methods for a property:
    * A getter - to access the value of the attribute.
    * A setter - to set the value of the attribute.
    * A deleter - to delete the instance attribute.
* By defining properties, you can change the internal implementation of a class without affecting the program, so you can add getters, setters, and deleters that act as intermediaries "behind the scenes" to avoid accessing or modifying the data directly.
* The @property lets a method to be accessed as an attribute instead of as a method with a '()'

Variable naming standard according to PEP 8:
* It's recommended that all function and method variable names be all lowercase with underscores (all_lower_case)
* Class names and exceptio names: CamelCase
* Global and local variables: all_lower_case
* Constants: ALL_CAPS
* Public variables/attributes - intended to be used by the importer of this module or user of this class: regular_lower_case
* Private variabes/attributes - intended for internal use by the module or class: _single_leading_underscore
* Private attributes that are intended to not be used in subclasses: __double_leading_underscore
* Magic attributes: __double_underscores__

Context Manager -  __with__ block:
* Some objects need to "clean up" when done
    * File object needs to close()
    * A network connection may need to close
    * A data-intensive operation may need to del the data
* __with__ provides a block that "cleans up" when exited
* this block also handles exceptions that occur within the block and can also excute code when entered
* When you use a with block in python, the object in the with statement gets its __enter__ method called, the block inside the with runs, and then the __exit__ gets called (optionally with exception info if one was raised).

Exceptions:
* Exceptions are an elegant mechanism for handling errors
* Because each exception has a type and we want to be precise about what we're trapping.
* The easiest way to know the error is just by causing (try) the error and seeing what type of exception results

Exception Types:
* ZeroDivisionError: integer divison or modulo by Zero
    * >>> 5/0
* NameError: name 'xx' is not defined
    * print(v) when v is not defined prior
* SyntaxError: EOL while scanning strin literal
    * print('hello)
* KeyError: 
    * mydict['a'] when a is not existing in the dict
* IndexError: list index out of range
    * mylist[4] when 4th element in the list doesn't exist
* etc

sys.argv:
* sys.argv is a list in Python that contains all the command-line arguments passed to the script
* To use sys.argv, you will first need to import sys module
* With the len(sys.argv) function, you can count the number of arguments
    * import sys
    * print ("Number of arguments:", len(sys.argv), "arguments")
    * print ("Argument List:", str(sys.argv))
    * $ python test.py arg1 arg2 arg3
    * Number of arguments: 4 arguments.
    * Argument List: ['test.py', 'arg1', 'arg2', 'arg3']
* example: python sample.py Hello Python 
    * sys.argv[0] == ‘sample.py’ 
    * sys.argv[1] == ‘Hello’ 
    * sys.argv[2] == ‘Python’

RegEx module - (import re):
* Python has a built-in package called re, which can be used to work with Regular Expressions
* The re module offers a set of functions that allows us to search a string for a match:
    * findall -	Returns a list containing all matches
        * ex - Print a list of all matches:--------------------------------------------->>> txt = "The rain in Spain"; x = re.findall("ai", txt)
    * search - Returns a Match object if there is a match anywhere in the string
        * ex - Search the string to see if it starts with "The" and ends with "Spain":-->>> txt = "The rain in Spain"; x = re.search("^The.*Spain$", txt)
    * split - Returns a list where the string has been split at each match
        * ex - Split at each white-space character:------------------------------------->>> txt = "The rain in Spain"; x = re.split("\s", txt)
    * sub - Replaces one or many matches with a string
        * ex - Replace every white-space character with the number 9:------------------->>> txt = "The rain in Spain"; x = re.sub("\s", "9", txt)

Python *args and **kwargs:
* In Python, we can pass a variable number of arguments to a function using special symbols. 
* We use *args and **kwargs as an argument when we are unsure about the number of arguments to pass in the functions
* It basically says that if you pass any arguments to the function or method the objects will be stored in a tuple called args or a dictionary called kwargs
* But we can also pass no arguments in which case args will be empty.
* There are two special symbols:
    *args (Non Keyword Arguments) - Receive multiple arguments as a tuple
        * ex: def my_sum(*args):
                return sum(args)

            print(my_sum(1, 2, 3, 4))
            print(my_sum(1, 2, 3, 4, 5, 6, 7, 8))

    **kwargs (Keyword Arguments) - Receive multiple keyword arguments as a dictionary, with the argument names as keys and their values as the corresponding dictionary values.
        * ex: def func_kwargs(**kwargs):
                print('kwargs: ', kwargs)
                print('type: ', type(kwargs))

              func_kwargs(key1=1, key2=2, key3=3)

Object Serialization:
* Serialization means persistent storage (i.e, to disk). Serialization is also referred to as object persistence and persistence means storing data between executions of a program
* Relational storage writes data to tables (e.g, relational database text files). That's a form of persistence but it's not object persistence.
* Object-based storage stores objects as they are used in code
* If what we've stored on disk is actually a Python object, then we can say that the object was made persistent
* In object serialization, instead of storing object values in tables we'll attempt to store our Python objects as objects.

Ways to object Serialization:
    * Pickle:
        * Pickle is probably operationally the simplest way to store Python objects
        * Pickle lets to store the whole object as it is without breaking out these elements by looping through them and/or then write each one to a line in the file or a row in database
        * Benefits:
            * We don't have to think of transferring the data to some other format. Just dump the object and then when we load it we get it back
            * Very convenient
        * Downsides:
            * Pickle file is not human readable
            * It's a bit slow to store/retrieve
            * Consumes a little additional space on disk
        * Python doesn't actually store module or class code and it doesn't store class variables either.
        * In other words - in pickling the instance, we haven't pickled the class and even pickling the class object itself is not going to help.
        * Pickle can't store code. It also doesn't store class attribute values.
        * So if you want to pickle an instance or a function or a module, the code for it actually needs to be available as pickle refers to the code

    * JSON (JavaScript Object Notation):
        * It was designed for javascript originally but has become popular across languages for this very reason that its Human readable and editable
        * Often used for configuration files
        * Caveats to be aware during editing of json files:
            * Unlike in Python, json reports error if there is a comma after the last element in the list
            * Single quotes are not allowed in json
            * The "true" value in a dictionary inside json isn't capitalized and in Python a value of "True" wouldn't be the true value if it wasn't capitalized.
            
    * YAML (YAML Ain't Markup Language)
        * Serializes Python objects, like Pickle or JSON
        * YAML denies that it is markup language as it uses whitespace to separate elements rather than using {} braces like other markup languages
        * Need to install Python's YAML parsing module Pyyaml to use YAML
        * We can load and dump multi-dimensional structures in a way similar to the way we did with Jason and pickle
        * In pickle/JSON, "dumps" and "loads" would work from the string or go to a string whereas dump and load just worked with a file handle or other file like object.
        * But in YAML, just the "dump" and "load" is enough. If you pass it a string, it will work with a string and if you pass it a file handle it'll work with the file handle

Python Debugger (PDB) Module: PDB is built-in to Python. There are IDE debuggers as well which provide visual means to debug but PDB is built-in option

Python Logging Module:
    * Writes logging "events" to file or the terminal screen
    * Messages are written and logged at levels of "severity":
        * DEBUG (debug()): diagnostic messages for development
        * INFO (info()): standard "progress" messages
        * WARNING (warning()): detected a non-serious issue
        * ERROR (error()): encountered an error, possibly serious
        * CRITICAL (critical()): usually a fatal error (program stops)
    * So what we do is we insert statements into our program and we set a severity level to each statement
    * Then when we're running our program we get to choose which log messages we'll see.
    * The default, if we don't set a level at all is warning

Benchmarking with timeit:
    * Benchmarking means comparing two code snippets to see which executes faster
    * Time and memory are often not a concern to us, but it is to some Python programmers
    * Sometimes when a script is running too long it could also mean that it's allocating too much memory or using memory inefficiently.
    * Time tests should be run multiple times
    * Tests should consider the context in which they will run

Pytest Module:
    * Software Testing:
        * The most basic form of software testing, tests the outcome of single functions or single method calls
        * Well-designed software usually consists of small units that are the functions and methods and it benefits in testing
        * If we can test each small unit in isolation we go a long way to verifying that that code is working properly
        * Unit Testing:
            * Each function or method is thought of as a testable unit so we call this approach unit testing
            * Unit tests are an essential requirement of quality code
            * Since code is so complex, we test the individual units in isolation
        * End to End Testing:
            * It will test the program as a whole
    * Pytest is the testing module that allows us to write scripts that test other scripts 
    * Python testing script simply imports another script, then calls each of its functions and methods and then asserts various things about the outcome.
    * Python tests are Python programs that test other Python programs
    * Pytest doesn't come installed with Python and it needs to be installed
    * Python has another built-in package called unit test but that is different from Pytest
    * The name "test" prepended to the name of our script and our function is required for Python to be able to find it when we first run pytest.
    * py.test looks for scripts functions/methods called test_
    * Python is going to look for any program whose name begins with test and inside that program for any function whose name begins with test. These functions/methods are units that are tested
    * After calling function or method, assert something is true
    * Assert:
        * assert is a simple statement, we often use it in out scripts (ex: assert 5 == 5)
        * If we pass a true statement to assert we get nothing back. And that's because the assert is designed to be silent.
        * If the assert statement is false, then we get an AssertionError
    * we run the test by executing "py.test" in the command prompt which will search for file prepending with "test_" and runs the test
    * with pytest.raises() to assert that an exception is raised
    * Test driven development approach is the one which you write the tests first and then you write the code to fulfill the test because it ensures that we have a very thorough
        testing suite to go along with the code that we write.
    * setup_class() method to do test prep
    * teardown_class() method to clean up after tests
    * Tests don't normally operate on live data because they may make changes in the process.
    * There are entities called fixtures that will mock data for the tests to use.
    * It's much cleaner and safer to have the tests operate on a temporary data set for this purpose and for any other process that prepares the environment for the test to run it.
    








